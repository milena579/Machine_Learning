{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import models, layers, activations, \\\n",
    "    optimizers, utils, losses, initializers, metrics, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\Users\\disrct\\Desktop\\Machine_Learning\\RedeNeural/train'\n",
    "epochs = 100\n",
    "batch_size = 32 #quantidade de dados\n",
    "patience = 5 #ira analisar o erro durante as épocas se ele não diminuir durante cinco épocas a paciencia acaba e da early stopping\n",
    "learning_rate = 0.001 #alfa do sgd\n",
    "model_path = 'C:\\Users\\disrct\\Desktop\\Machine_Learning\\RedeNeural\\train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  models.Sequential([\n",
    "    #Camadas de convulsao\n",
    "    layers.Resizing(56, 56), #muda o tamanho de todas as imagens padronizando elas\n",
    "    layers.Rescaling(1.0/255),#muda os valores do pixel e deixa entre 0 e 1\n",
    "    layers.RandomRotation((-0.2, 0.2)), #muda a rotação da imagem, girando ela e vendo de outros angulos\n",
    "\n",
    "    layers.Conv2D(32, (3, 3), #aplicação dos filtros serão 32 filtros 3x3\n",
    "        activation =  'relu',\n",
    "        kernel_initializer =  initializers.RandomNormal()\n",
    "    ),\n",
    "    layers.MaxPooling2D((2, 2)), #pega o valor maximo de cada quadrado nessa caso 2x2\n",
    "\n",
    "    layers.Conv2D(64, (4, 4), #2048 @ 24x24 64 filtros x 32 imgs\n",
    "        activation =  'relu',\n",
    "        kernel_initializer =  initializers.RandomNormal()          \n",
    "    ),\n",
    "    layers.MaxPooling2D((3, 3)), #2048 @ 8x8\n",
    "\n",
    "    layers.Flatten(), #pega todos os valores e transforma em um vetor gigante +- 125k\n",
    "\n",
    "    layers.Dropout(0.2), # a cada época serão dropados 20% dos neuronios\n",
    "\n",
    "    #Camada de processamento\n",
    "    layers.Dense(128,\n",
    "        activation =  'relu',\n",
    "        kernel_initializer =  initializers.RandomNormal()  \n",
    "    ),\n",
    "                  \n",
    "    layers.Dense(64,\n",
    "        activation =  'relu',\n",
    "        kernel_initializer =  initializers.RandomNormal()  \n",
    "    ),\n",
    "\n",
    "    layers.Dense(64,\n",
    "        activation =  'relu',\n",
    "        kernel_initializer =  initializers.RandomNormal()  \n",
    "    ),\n",
    "\n",
    "    layers.Dense(1,\n",
    "        activation =  'sigmoid',\n",
    "        kernel_initializer =  initializers.RandomNormal()  \n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = optimizers.Adam(\n",
    "        learning_rate = learning_rate\n",
    "    ),\n",
    "    loss = losses.BinaryCrossentropy(),\n",
    "    metrics = [\n",
    "        metrics.BinaryAccuracy(),\n",
    "        metrics.Precision(),\n",
    "        metrics.Recall()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = utils.image_dataset_from_directory(\n",
    "    path,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    shuffle = True,\n",
    "    seed = 42,\n",
    "    image_size = (224, 224),\n",
    "    batch_size = batch_size \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = utils.image_dataset_from_directory(\n",
    "    path,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    shuffle = True,\n",
    "    seed = 42,\n",
    "    image_size = (224, 224),\n",
    "    batch_size = batch_size \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train,\n",
    "    validation_data = test,\n",
    "    epochs = epochs,\n",
    "    callbacks = [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss',\n",
    "            patience = patience,\n",
    "            verbose = 1\n",
    "        )\n",
    "        # callbacks.ModelCheckpoint(\n",
    "        #     filepath = model_path,\n",
    "        #     save_weights_only = False,\n",
    "        #     monitor = 'loss',\n",
    "        #     mode = 'min',\n",
    "        #     save_best_only = True\n",
    "        # )\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
